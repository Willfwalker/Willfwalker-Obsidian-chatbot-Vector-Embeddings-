/*
THIS IS A GENERATED/BUNDLED FILE BY ESBUILD
if you want to view the source, please visit the github repository of this plugin
*/

var __defProp = Object.defineProperty;
var __getOwnPropDesc = Object.getOwnPropertyDescriptor;
var __getOwnPropNames = Object.getOwnPropertyNames;
var __hasOwnProp = Object.prototype.hasOwnProperty;
var __export = (target, all) => {
  for (var name in all)
    __defProp(target, name, { get: all[name], enumerable: true });
};
var __copyProps = (to, from, except, desc) => {
  if (from && typeof from === "object" || typeof from === "function") {
    for (let key of __getOwnPropNames(from))
      if (!__hasOwnProp.call(to, key) && key !== except)
        __defProp(to, key, { get: () => from[key], enumerable: !(desc = __getOwnPropDesc(from, key)) || desc.enumerable });
  }
  return to;
};
var __toCommonJS = (mod) => __copyProps(__defProp({}, "__esModule", { value: true }), mod);

// main.ts
var main_exports = {};
__export(main_exports, {
  default: () => GeminiVectorChatPlugin
});
module.exports = __toCommonJS(main_exports);
var import_obsidian3 = require("obsidian");

// node_modules/@google/generative-ai/dist/index.mjs
var SchemaType;
(function(SchemaType2) {
  SchemaType2["STRING"] = "string";
  SchemaType2["NUMBER"] = "number";
  SchemaType2["INTEGER"] = "integer";
  SchemaType2["BOOLEAN"] = "boolean";
  SchemaType2["ARRAY"] = "array";
  SchemaType2["OBJECT"] = "object";
})(SchemaType || (SchemaType = {}));
var ExecutableCodeLanguage;
(function(ExecutableCodeLanguage2) {
  ExecutableCodeLanguage2["LANGUAGE_UNSPECIFIED"] = "language_unspecified";
  ExecutableCodeLanguage2["PYTHON"] = "python";
})(ExecutableCodeLanguage || (ExecutableCodeLanguage = {}));
var Outcome;
(function(Outcome2) {
  Outcome2["OUTCOME_UNSPECIFIED"] = "outcome_unspecified";
  Outcome2["OUTCOME_OK"] = "outcome_ok";
  Outcome2["OUTCOME_FAILED"] = "outcome_failed";
  Outcome2["OUTCOME_DEADLINE_EXCEEDED"] = "outcome_deadline_exceeded";
})(Outcome || (Outcome = {}));
var POSSIBLE_ROLES = ["user", "model", "function", "system"];
var HarmCategory;
(function(HarmCategory2) {
  HarmCategory2["HARM_CATEGORY_UNSPECIFIED"] = "HARM_CATEGORY_UNSPECIFIED";
  HarmCategory2["HARM_CATEGORY_HATE_SPEECH"] = "HARM_CATEGORY_HATE_SPEECH";
  HarmCategory2["HARM_CATEGORY_SEXUALLY_EXPLICIT"] = "HARM_CATEGORY_SEXUALLY_EXPLICIT";
  HarmCategory2["HARM_CATEGORY_HARASSMENT"] = "HARM_CATEGORY_HARASSMENT";
  HarmCategory2["HARM_CATEGORY_DANGEROUS_CONTENT"] = "HARM_CATEGORY_DANGEROUS_CONTENT";
})(HarmCategory || (HarmCategory = {}));
var HarmBlockThreshold;
(function(HarmBlockThreshold2) {
  HarmBlockThreshold2["HARM_BLOCK_THRESHOLD_UNSPECIFIED"] = "HARM_BLOCK_THRESHOLD_UNSPECIFIED";
  HarmBlockThreshold2["BLOCK_LOW_AND_ABOVE"] = "BLOCK_LOW_AND_ABOVE";
  HarmBlockThreshold2["BLOCK_MEDIUM_AND_ABOVE"] = "BLOCK_MEDIUM_AND_ABOVE";
  HarmBlockThreshold2["BLOCK_ONLY_HIGH"] = "BLOCK_ONLY_HIGH";
  HarmBlockThreshold2["BLOCK_NONE"] = "BLOCK_NONE";
})(HarmBlockThreshold || (HarmBlockThreshold = {}));
var HarmProbability;
(function(HarmProbability2) {
  HarmProbability2["HARM_PROBABILITY_UNSPECIFIED"] = "HARM_PROBABILITY_UNSPECIFIED";
  HarmProbability2["NEGLIGIBLE"] = "NEGLIGIBLE";
  HarmProbability2["LOW"] = "LOW";
  HarmProbability2["MEDIUM"] = "MEDIUM";
  HarmProbability2["HIGH"] = "HIGH";
})(HarmProbability || (HarmProbability = {}));
var BlockReason;
(function(BlockReason2) {
  BlockReason2["BLOCKED_REASON_UNSPECIFIED"] = "BLOCKED_REASON_UNSPECIFIED";
  BlockReason2["SAFETY"] = "SAFETY";
  BlockReason2["OTHER"] = "OTHER";
})(BlockReason || (BlockReason = {}));
var FinishReason;
(function(FinishReason2) {
  FinishReason2["FINISH_REASON_UNSPECIFIED"] = "FINISH_REASON_UNSPECIFIED";
  FinishReason2["STOP"] = "STOP";
  FinishReason2["MAX_TOKENS"] = "MAX_TOKENS";
  FinishReason2["SAFETY"] = "SAFETY";
  FinishReason2["RECITATION"] = "RECITATION";
  FinishReason2["LANGUAGE"] = "LANGUAGE";
  FinishReason2["OTHER"] = "OTHER";
})(FinishReason || (FinishReason = {}));
var TaskType;
(function(TaskType2) {
  TaskType2["TASK_TYPE_UNSPECIFIED"] = "TASK_TYPE_UNSPECIFIED";
  TaskType2["RETRIEVAL_QUERY"] = "RETRIEVAL_QUERY";
  TaskType2["RETRIEVAL_DOCUMENT"] = "RETRIEVAL_DOCUMENT";
  TaskType2["SEMANTIC_SIMILARITY"] = "SEMANTIC_SIMILARITY";
  TaskType2["CLASSIFICATION"] = "CLASSIFICATION";
  TaskType2["CLUSTERING"] = "CLUSTERING";
})(TaskType || (TaskType = {}));
var FunctionCallingMode;
(function(FunctionCallingMode2) {
  FunctionCallingMode2["MODE_UNSPECIFIED"] = "MODE_UNSPECIFIED";
  FunctionCallingMode2["AUTO"] = "AUTO";
  FunctionCallingMode2["ANY"] = "ANY";
  FunctionCallingMode2["NONE"] = "NONE";
})(FunctionCallingMode || (FunctionCallingMode = {}));
var DynamicRetrievalMode;
(function(DynamicRetrievalMode2) {
  DynamicRetrievalMode2["MODE_UNSPECIFIED"] = "MODE_UNSPECIFIED";
  DynamicRetrievalMode2["MODE_DYNAMIC"] = "MODE_DYNAMIC";
})(DynamicRetrievalMode || (DynamicRetrievalMode = {}));
var GoogleGenerativeAIError = class extends Error {
  constructor(message) {
    super(`[GoogleGenerativeAI Error]: ${message}`);
  }
};
var GoogleGenerativeAIResponseError = class extends GoogleGenerativeAIError {
  constructor(message, response) {
    super(message);
    this.response = response;
  }
};
var GoogleGenerativeAIFetchError = class extends GoogleGenerativeAIError {
  constructor(message, status, statusText, errorDetails) {
    super(message);
    this.status = status;
    this.statusText = statusText;
    this.errorDetails = errorDetails;
  }
};
var GoogleGenerativeAIRequestInputError = class extends GoogleGenerativeAIError {
};
var DEFAULT_BASE_URL = "https://generativelanguage.googleapis.com";
var DEFAULT_API_VERSION = "v1beta";
var PACKAGE_VERSION = "0.21.0";
var PACKAGE_LOG_HEADER = "genai-js";
var Task;
(function(Task2) {
  Task2["GENERATE_CONTENT"] = "generateContent";
  Task2["STREAM_GENERATE_CONTENT"] = "streamGenerateContent";
  Task2["COUNT_TOKENS"] = "countTokens";
  Task2["EMBED_CONTENT"] = "embedContent";
  Task2["BATCH_EMBED_CONTENTS"] = "batchEmbedContents";
})(Task || (Task = {}));
var RequestUrl = class {
  constructor(model, task, apiKey, stream, requestOptions) {
    this.model = model;
    this.task = task;
    this.apiKey = apiKey;
    this.stream = stream;
    this.requestOptions = requestOptions;
  }
  toString() {
    var _a, _b;
    const apiVersion = ((_a = this.requestOptions) === null || _a === void 0 ? void 0 : _a.apiVersion) || DEFAULT_API_VERSION;
    const baseUrl = ((_b = this.requestOptions) === null || _b === void 0 ? void 0 : _b.baseUrl) || DEFAULT_BASE_URL;
    let url = `${baseUrl}/${apiVersion}/${this.model}:${this.task}`;
    if (this.stream) {
      url += "?alt=sse";
    }
    return url;
  }
};
function getClientHeaders(requestOptions) {
  const clientHeaders = [];
  if (requestOptions === null || requestOptions === void 0 ? void 0 : requestOptions.apiClient) {
    clientHeaders.push(requestOptions.apiClient);
  }
  clientHeaders.push(`${PACKAGE_LOG_HEADER}/${PACKAGE_VERSION}`);
  return clientHeaders.join(" ");
}
async function getHeaders(url) {
  var _a;
  const headers = new Headers();
  headers.append("Content-Type", "application/json");
  headers.append("x-goog-api-client", getClientHeaders(url.requestOptions));
  headers.append("x-goog-api-key", url.apiKey);
  let customHeaders = (_a = url.requestOptions) === null || _a === void 0 ? void 0 : _a.customHeaders;
  if (customHeaders) {
    if (!(customHeaders instanceof Headers)) {
      try {
        customHeaders = new Headers(customHeaders);
      } catch (e) {
        throw new GoogleGenerativeAIRequestInputError(`unable to convert customHeaders value ${JSON.stringify(customHeaders)} to Headers: ${e.message}`);
      }
    }
    for (const [headerName, headerValue] of customHeaders.entries()) {
      if (headerName === "x-goog-api-key") {
        throw new GoogleGenerativeAIRequestInputError(`Cannot set reserved header name ${headerName}`);
      } else if (headerName === "x-goog-api-client") {
        throw new GoogleGenerativeAIRequestInputError(`Header name ${headerName} can only be set using the apiClient field`);
      }
      headers.append(headerName, headerValue);
    }
  }
  return headers;
}
async function constructModelRequest(model, task, apiKey, stream, body, requestOptions) {
  const url = new RequestUrl(model, task, apiKey, stream, requestOptions);
  return {
    url: url.toString(),
    fetchOptions: Object.assign(Object.assign({}, buildFetchOptions(requestOptions)), { method: "POST", headers: await getHeaders(url), body })
  };
}
async function makeModelRequest(model, task, apiKey, stream, body, requestOptions = {}, fetchFn = fetch) {
  const { url, fetchOptions } = await constructModelRequest(model, task, apiKey, stream, body, requestOptions);
  return makeRequest(url, fetchOptions, fetchFn);
}
async function makeRequest(url, fetchOptions, fetchFn = fetch) {
  let response;
  try {
    response = await fetchFn(url, fetchOptions);
  } catch (e) {
    handleResponseError(e, url);
  }
  if (!response.ok) {
    await handleResponseNotOk(response, url);
  }
  return response;
}
function handleResponseError(e, url) {
  let err = e;
  if (!(e instanceof GoogleGenerativeAIFetchError || e instanceof GoogleGenerativeAIRequestInputError)) {
    err = new GoogleGenerativeAIError(`Error fetching from ${url.toString()}: ${e.message}`);
    err.stack = e.stack;
  }
  throw err;
}
async function handleResponseNotOk(response, url) {
  let message = "";
  let errorDetails;
  try {
    const json = await response.json();
    message = json.error.message;
    if (json.error.details) {
      message += ` ${JSON.stringify(json.error.details)}`;
      errorDetails = json.error.details;
    }
  } catch (e) {
  }
  throw new GoogleGenerativeAIFetchError(`Error fetching from ${url.toString()}: [${response.status} ${response.statusText}] ${message}`, response.status, response.statusText, errorDetails);
}
function buildFetchOptions(requestOptions) {
  const fetchOptions = {};
  if ((requestOptions === null || requestOptions === void 0 ? void 0 : requestOptions.signal) !== void 0 || (requestOptions === null || requestOptions === void 0 ? void 0 : requestOptions.timeout) >= 0) {
    const controller = new AbortController();
    if ((requestOptions === null || requestOptions === void 0 ? void 0 : requestOptions.timeout) >= 0) {
      setTimeout(() => controller.abort(), requestOptions.timeout);
    }
    if (requestOptions === null || requestOptions === void 0 ? void 0 : requestOptions.signal) {
      requestOptions.signal.addEventListener("abort", () => {
        controller.abort();
      });
    }
    fetchOptions.signal = controller.signal;
  }
  return fetchOptions;
}
function addHelpers(response) {
  response.text = () => {
    if (response.candidates && response.candidates.length > 0) {
      if (response.candidates.length > 1) {
        console.warn(`This response had ${response.candidates.length} candidates. Returning text from the first candidate only. Access response.candidates directly to use the other candidates.`);
      }
      if (hadBadFinishReason(response.candidates[0])) {
        throw new GoogleGenerativeAIResponseError(`${formatBlockErrorMessage(response)}`, response);
      }
      return getText(response);
    } else if (response.promptFeedback) {
      throw new GoogleGenerativeAIResponseError(`Text not available. ${formatBlockErrorMessage(response)}`, response);
    }
    return "";
  };
  response.functionCall = () => {
    if (response.candidates && response.candidates.length > 0) {
      if (response.candidates.length > 1) {
        console.warn(`This response had ${response.candidates.length} candidates. Returning function calls from the first candidate only. Access response.candidates directly to use the other candidates.`);
      }
      if (hadBadFinishReason(response.candidates[0])) {
        throw new GoogleGenerativeAIResponseError(`${formatBlockErrorMessage(response)}`, response);
      }
      console.warn(`response.functionCall() is deprecated. Use response.functionCalls() instead.`);
      return getFunctionCalls(response)[0];
    } else if (response.promptFeedback) {
      throw new GoogleGenerativeAIResponseError(`Function call not available. ${formatBlockErrorMessage(response)}`, response);
    }
    return void 0;
  };
  response.functionCalls = () => {
    if (response.candidates && response.candidates.length > 0) {
      if (response.candidates.length > 1) {
        console.warn(`This response had ${response.candidates.length} candidates. Returning function calls from the first candidate only. Access response.candidates directly to use the other candidates.`);
      }
      if (hadBadFinishReason(response.candidates[0])) {
        throw new GoogleGenerativeAIResponseError(`${formatBlockErrorMessage(response)}`, response);
      }
      return getFunctionCalls(response);
    } else if (response.promptFeedback) {
      throw new GoogleGenerativeAIResponseError(`Function call not available. ${formatBlockErrorMessage(response)}`, response);
    }
    return void 0;
  };
  return response;
}
function getText(response) {
  var _a, _b, _c, _d;
  const textStrings = [];
  if ((_b = (_a = response.candidates) === null || _a === void 0 ? void 0 : _a[0].content) === null || _b === void 0 ? void 0 : _b.parts) {
    for (const part of (_d = (_c = response.candidates) === null || _c === void 0 ? void 0 : _c[0].content) === null || _d === void 0 ? void 0 : _d.parts) {
      if (part.text) {
        textStrings.push(part.text);
      }
      if (part.executableCode) {
        textStrings.push("\n```" + part.executableCode.language + "\n" + part.executableCode.code + "\n```\n");
      }
      if (part.codeExecutionResult) {
        textStrings.push("\n```\n" + part.codeExecutionResult.output + "\n```\n");
      }
    }
  }
  if (textStrings.length > 0) {
    return textStrings.join("");
  } else {
    return "";
  }
}
function getFunctionCalls(response) {
  var _a, _b, _c, _d;
  const functionCalls = [];
  if ((_b = (_a = response.candidates) === null || _a === void 0 ? void 0 : _a[0].content) === null || _b === void 0 ? void 0 : _b.parts) {
    for (const part of (_d = (_c = response.candidates) === null || _c === void 0 ? void 0 : _c[0].content) === null || _d === void 0 ? void 0 : _d.parts) {
      if (part.functionCall) {
        functionCalls.push(part.functionCall);
      }
    }
  }
  if (functionCalls.length > 0) {
    return functionCalls;
  } else {
    return void 0;
  }
}
var badFinishReasons = [
  FinishReason.RECITATION,
  FinishReason.SAFETY,
  FinishReason.LANGUAGE
];
function hadBadFinishReason(candidate) {
  return !!candidate.finishReason && badFinishReasons.includes(candidate.finishReason);
}
function formatBlockErrorMessage(response) {
  var _a, _b, _c;
  let message = "";
  if ((!response.candidates || response.candidates.length === 0) && response.promptFeedback) {
    message += "Response was blocked";
    if ((_a = response.promptFeedback) === null || _a === void 0 ? void 0 : _a.blockReason) {
      message += ` due to ${response.promptFeedback.blockReason}`;
    }
    if ((_b = response.promptFeedback) === null || _b === void 0 ? void 0 : _b.blockReasonMessage) {
      message += `: ${response.promptFeedback.blockReasonMessage}`;
    }
  } else if ((_c = response.candidates) === null || _c === void 0 ? void 0 : _c[0]) {
    const firstCandidate = response.candidates[0];
    if (hadBadFinishReason(firstCandidate)) {
      message += `Candidate was blocked due to ${firstCandidate.finishReason}`;
      if (firstCandidate.finishMessage) {
        message += `: ${firstCandidate.finishMessage}`;
      }
    }
  }
  return message;
}
function __await(v) {
  return this instanceof __await ? (this.v = v, this) : new __await(v);
}
function __asyncGenerator(thisArg, _arguments, generator) {
  if (!Symbol.asyncIterator)
    throw new TypeError("Symbol.asyncIterator is not defined.");
  var g = generator.apply(thisArg, _arguments || []), i, q = [];
  return i = {}, verb("next"), verb("throw"), verb("return"), i[Symbol.asyncIterator] = function() {
    return this;
  }, i;
  function verb(n) {
    if (g[n])
      i[n] = function(v) {
        return new Promise(function(a, b) {
          q.push([n, v, a, b]) > 1 || resume(n, v);
        });
      };
  }
  function resume(n, v) {
    try {
      step(g[n](v));
    } catch (e) {
      settle(q[0][3], e);
    }
  }
  function step(r) {
    r.value instanceof __await ? Promise.resolve(r.value.v).then(fulfill, reject) : settle(q[0][2], r);
  }
  function fulfill(value) {
    resume("next", value);
  }
  function reject(value) {
    resume("throw", value);
  }
  function settle(f, v) {
    if (f(v), q.shift(), q.length)
      resume(q[0][0], q[0][1]);
  }
}
var responseLineRE = /^data\: (.*)(?:\n\n|\r\r|\r\n\r\n)/;
function processStream(response) {
  const inputStream = response.body.pipeThrough(new TextDecoderStream("utf8", { fatal: true }));
  const responseStream = getResponseStream(inputStream);
  const [stream1, stream2] = responseStream.tee();
  return {
    stream: generateResponseSequence(stream1),
    response: getResponsePromise(stream2)
  };
}
async function getResponsePromise(stream) {
  const allResponses = [];
  const reader = stream.getReader();
  while (true) {
    const { done, value } = await reader.read();
    if (done) {
      return addHelpers(aggregateResponses(allResponses));
    }
    allResponses.push(value);
  }
}
function generateResponseSequence(stream) {
  return __asyncGenerator(this, arguments, function* generateResponseSequence_1() {
    const reader = stream.getReader();
    while (true) {
      const { value, done } = yield __await(reader.read());
      if (done) {
        break;
      }
      yield yield __await(addHelpers(value));
    }
  });
}
function getResponseStream(inputStream) {
  const reader = inputStream.getReader();
  const stream = new ReadableStream({
    start(controller) {
      let currentText = "";
      return pump();
      function pump() {
        return reader.read().then(({ value, done }) => {
          if (done) {
            if (currentText.trim()) {
              controller.error(new GoogleGenerativeAIError("Failed to parse stream"));
              return;
            }
            controller.close();
            return;
          }
          currentText += value;
          let match = currentText.match(responseLineRE);
          let parsedResponse;
          while (match) {
            try {
              parsedResponse = JSON.parse(match[1]);
            } catch (e) {
              controller.error(new GoogleGenerativeAIError(`Error parsing JSON response: "${match[1]}"`));
              return;
            }
            controller.enqueue(parsedResponse);
            currentText = currentText.substring(match[0].length);
            match = currentText.match(responseLineRE);
          }
          return pump();
        });
      }
    }
  });
  return stream;
}
function aggregateResponses(responses) {
  const lastResponse = responses[responses.length - 1];
  const aggregatedResponse = {
    promptFeedback: lastResponse === null || lastResponse === void 0 ? void 0 : lastResponse.promptFeedback
  };
  for (const response of responses) {
    if (response.candidates) {
      for (const candidate of response.candidates) {
        const i = candidate.index;
        if (!aggregatedResponse.candidates) {
          aggregatedResponse.candidates = [];
        }
        if (!aggregatedResponse.candidates[i]) {
          aggregatedResponse.candidates[i] = {
            index: candidate.index
          };
        }
        aggregatedResponse.candidates[i].citationMetadata = candidate.citationMetadata;
        aggregatedResponse.candidates[i].groundingMetadata = candidate.groundingMetadata;
        aggregatedResponse.candidates[i].finishReason = candidate.finishReason;
        aggregatedResponse.candidates[i].finishMessage = candidate.finishMessage;
        aggregatedResponse.candidates[i].safetyRatings = candidate.safetyRatings;
        if (candidate.content && candidate.content.parts) {
          if (!aggregatedResponse.candidates[i].content) {
            aggregatedResponse.candidates[i].content = {
              role: candidate.content.role || "user",
              parts: []
            };
          }
          const newPart = {};
          for (const part of candidate.content.parts) {
            if (part.text) {
              newPart.text = part.text;
            }
            if (part.functionCall) {
              newPart.functionCall = part.functionCall;
            }
            if (part.executableCode) {
              newPart.executableCode = part.executableCode;
            }
            if (part.codeExecutionResult) {
              newPart.codeExecutionResult = part.codeExecutionResult;
            }
            if (Object.keys(newPart).length === 0) {
              newPart.text = "";
            }
            aggregatedResponse.candidates[i].content.parts.push(newPart);
          }
        }
      }
    }
    if (response.usageMetadata) {
      aggregatedResponse.usageMetadata = response.usageMetadata;
    }
  }
  return aggregatedResponse;
}
async function generateContentStream(apiKey, model, params, requestOptions) {
  const response = await makeModelRequest(
    model,
    Task.STREAM_GENERATE_CONTENT,
    apiKey,
    /* stream */
    true,
    JSON.stringify(params),
    requestOptions
  );
  return processStream(response);
}
async function generateContent(apiKey, model, params, requestOptions) {
  const response = await makeModelRequest(
    model,
    Task.GENERATE_CONTENT,
    apiKey,
    /* stream */
    false,
    JSON.stringify(params),
    requestOptions
  );
  const responseJson = await response.json();
  const enhancedResponse = addHelpers(responseJson);
  return {
    response: enhancedResponse
  };
}
function formatSystemInstruction(input) {
  if (input == null) {
    return void 0;
  } else if (typeof input === "string") {
    return { role: "system", parts: [{ text: input }] };
  } else if (input.text) {
    return { role: "system", parts: [input] };
  } else if (input.parts) {
    if (!input.role) {
      return { role: "system", parts: input.parts };
    } else {
      return input;
    }
  }
}
function formatNewContent(request) {
  let newParts = [];
  if (typeof request === "string") {
    newParts = [{ text: request }];
  } else {
    for (const partOrString of request) {
      if (typeof partOrString === "string") {
        newParts.push({ text: partOrString });
      } else {
        newParts.push(partOrString);
      }
    }
  }
  return assignRoleToPartsAndValidateSendMessageRequest(newParts);
}
function assignRoleToPartsAndValidateSendMessageRequest(parts) {
  const userContent = { role: "user", parts: [] };
  const functionContent = { role: "function", parts: [] };
  let hasUserContent = false;
  let hasFunctionContent = false;
  for (const part of parts) {
    if ("functionResponse" in part) {
      functionContent.parts.push(part);
      hasFunctionContent = true;
    } else {
      userContent.parts.push(part);
      hasUserContent = true;
    }
  }
  if (hasUserContent && hasFunctionContent) {
    throw new GoogleGenerativeAIError("Within a single message, FunctionResponse cannot be mixed with other type of part in the request for sending chat message.");
  }
  if (!hasUserContent && !hasFunctionContent) {
    throw new GoogleGenerativeAIError("No content is provided for sending chat message.");
  }
  if (hasUserContent) {
    return userContent;
  }
  return functionContent;
}
function formatCountTokensInput(params, modelParams) {
  var _a;
  let formattedGenerateContentRequest = {
    model: modelParams === null || modelParams === void 0 ? void 0 : modelParams.model,
    generationConfig: modelParams === null || modelParams === void 0 ? void 0 : modelParams.generationConfig,
    safetySettings: modelParams === null || modelParams === void 0 ? void 0 : modelParams.safetySettings,
    tools: modelParams === null || modelParams === void 0 ? void 0 : modelParams.tools,
    toolConfig: modelParams === null || modelParams === void 0 ? void 0 : modelParams.toolConfig,
    systemInstruction: modelParams === null || modelParams === void 0 ? void 0 : modelParams.systemInstruction,
    cachedContent: (_a = modelParams === null || modelParams === void 0 ? void 0 : modelParams.cachedContent) === null || _a === void 0 ? void 0 : _a.name,
    contents: []
  };
  const containsGenerateContentRequest = params.generateContentRequest != null;
  if (params.contents) {
    if (containsGenerateContentRequest) {
      throw new GoogleGenerativeAIRequestInputError("CountTokensRequest must have one of contents or generateContentRequest, not both.");
    }
    formattedGenerateContentRequest.contents = params.contents;
  } else if (containsGenerateContentRequest) {
    formattedGenerateContentRequest = Object.assign(Object.assign({}, formattedGenerateContentRequest), params.generateContentRequest);
  } else {
    const content = formatNewContent(params);
    formattedGenerateContentRequest.contents = [content];
  }
  return { generateContentRequest: formattedGenerateContentRequest };
}
function formatGenerateContentInput(params) {
  let formattedRequest;
  if (params.contents) {
    formattedRequest = params;
  } else {
    const content = formatNewContent(params);
    formattedRequest = { contents: [content] };
  }
  if (params.systemInstruction) {
    formattedRequest.systemInstruction = formatSystemInstruction(params.systemInstruction);
  }
  return formattedRequest;
}
function formatEmbedContentInput(params) {
  if (typeof params === "string" || Array.isArray(params)) {
    const content = formatNewContent(params);
    return { content };
  }
  return params;
}
var VALID_PART_FIELDS = [
  "text",
  "inlineData",
  "functionCall",
  "functionResponse",
  "executableCode",
  "codeExecutionResult"
];
var VALID_PARTS_PER_ROLE = {
  user: ["text", "inlineData"],
  function: ["functionResponse"],
  model: ["text", "functionCall", "executableCode", "codeExecutionResult"],
  // System instructions shouldn't be in history anyway.
  system: ["text"]
};
function validateChatHistory(history) {
  let prevContent = false;
  for (const currContent of history) {
    const { role, parts } = currContent;
    if (!prevContent && role !== "user") {
      throw new GoogleGenerativeAIError(`First content should be with role 'user', got ${role}`);
    }
    if (!POSSIBLE_ROLES.includes(role)) {
      throw new GoogleGenerativeAIError(`Each item should include role field. Got ${role} but valid roles are: ${JSON.stringify(POSSIBLE_ROLES)}`);
    }
    if (!Array.isArray(parts)) {
      throw new GoogleGenerativeAIError("Content should have 'parts' property with an array of Parts");
    }
    if (parts.length === 0) {
      throw new GoogleGenerativeAIError("Each Content should have at least one part");
    }
    const countFields = {
      text: 0,
      inlineData: 0,
      functionCall: 0,
      functionResponse: 0,
      fileData: 0,
      executableCode: 0,
      codeExecutionResult: 0
    };
    for (const part of parts) {
      for (const key of VALID_PART_FIELDS) {
        if (key in part) {
          countFields[key] += 1;
        }
      }
    }
    const validParts = VALID_PARTS_PER_ROLE[role];
    for (const key of VALID_PART_FIELDS) {
      if (!validParts.includes(key) && countFields[key] > 0) {
        throw new GoogleGenerativeAIError(`Content with role '${role}' can't contain '${key}' part`);
      }
    }
    prevContent = true;
  }
}
var SILENT_ERROR = "SILENT_ERROR";
var ChatSession = class {
  constructor(apiKey, model, params, _requestOptions = {}) {
    this.model = model;
    this.params = params;
    this._requestOptions = _requestOptions;
    this._history = [];
    this._sendPromise = Promise.resolve();
    this._apiKey = apiKey;
    if (params === null || params === void 0 ? void 0 : params.history) {
      validateChatHistory(params.history);
      this._history = params.history;
    }
  }
  /**
   * Gets the chat history so far. Blocked prompts are not added to history.
   * Blocked candidates are not added to history, nor are the prompts that
   * generated them.
   */
  async getHistory() {
    await this._sendPromise;
    return this._history;
  }
  /**
   * Sends a chat message and receives a non-streaming
   * {@link GenerateContentResult}.
   *
   * Fields set in the optional {@link SingleRequestOptions} parameter will
   * take precedence over the {@link RequestOptions} values provided to
   * {@link GoogleGenerativeAI.getGenerativeModel }.
   */
  async sendMessage(request, requestOptions = {}) {
    var _a, _b, _c, _d, _e, _f;
    await this._sendPromise;
    const newContent = formatNewContent(request);
    const generateContentRequest = {
      safetySettings: (_a = this.params) === null || _a === void 0 ? void 0 : _a.safetySettings,
      generationConfig: (_b = this.params) === null || _b === void 0 ? void 0 : _b.generationConfig,
      tools: (_c = this.params) === null || _c === void 0 ? void 0 : _c.tools,
      toolConfig: (_d = this.params) === null || _d === void 0 ? void 0 : _d.toolConfig,
      systemInstruction: (_e = this.params) === null || _e === void 0 ? void 0 : _e.systemInstruction,
      cachedContent: (_f = this.params) === null || _f === void 0 ? void 0 : _f.cachedContent,
      contents: [...this._history, newContent]
    };
    const chatSessionRequestOptions = Object.assign(Object.assign({}, this._requestOptions), requestOptions);
    let finalResult;
    this._sendPromise = this._sendPromise.then(() => generateContent(this._apiKey, this.model, generateContentRequest, chatSessionRequestOptions)).then((result) => {
      var _a2;
      if (result.response.candidates && result.response.candidates.length > 0) {
        this._history.push(newContent);
        const responseContent = Object.assign({
          parts: [],
          // Response seems to come back without a role set.
          role: "model"
        }, (_a2 = result.response.candidates) === null || _a2 === void 0 ? void 0 : _a2[0].content);
        this._history.push(responseContent);
      } else {
        const blockErrorMessage = formatBlockErrorMessage(result.response);
        if (blockErrorMessage) {
          console.warn(`sendMessage() was unsuccessful. ${blockErrorMessage}. Inspect response object for details.`);
        }
      }
      finalResult = result;
    });
    await this._sendPromise;
    return finalResult;
  }
  /**
   * Sends a chat message and receives the response as a
   * {@link GenerateContentStreamResult} containing an iterable stream
   * and a response promise.
   *
   * Fields set in the optional {@link SingleRequestOptions} parameter will
   * take precedence over the {@link RequestOptions} values provided to
   * {@link GoogleGenerativeAI.getGenerativeModel }.
   */
  async sendMessageStream(request, requestOptions = {}) {
    var _a, _b, _c, _d, _e, _f;
    await this._sendPromise;
    const newContent = formatNewContent(request);
    const generateContentRequest = {
      safetySettings: (_a = this.params) === null || _a === void 0 ? void 0 : _a.safetySettings,
      generationConfig: (_b = this.params) === null || _b === void 0 ? void 0 : _b.generationConfig,
      tools: (_c = this.params) === null || _c === void 0 ? void 0 : _c.tools,
      toolConfig: (_d = this.params) === null || _d === void 0 ? void 0 : _d.toolConfig,
      systemInstruction: (_e = this.params) === null || _e === void 0 ? void 0 : _e.systemInstruction,
      cachedContent: (_f = this.params) === null || _f === void 0 ? void 0 : _f.cachedContent,
      contents: [...this._history, newContent]
    };
    const chatSessionRequestOptions = Object.assign(Object.assign({}, this._requestOptions), requestOptions);
    const streamPromise = generateContentStream(this._apiKey, this.model, generateContentRequest, chatSessionRequestOptions);
    this._sendPromise = this._sendPromise.then(() => streamPromise).catch((_ignored) => {
      throw new Error(SILENT_ERROR);
    }).then((streamResult) => streamResult.response).then((response) => {
      if (response.candidates && response.candidates.length > 0) {
        this._history.push(newContent);
        const responseContent = Object.assign({}, response.candidates[0].content);
        if (!responseContent.role) {
          responseContent.role = "model";
        }
        this._history.push(responseContent);
      } else {
        const blockErrorMessage = formatBlockErrorMessage(response);
        if (blockErrorMessage) {
          console.warn(`sendMessageStream() was unsuccessful. ${blockErrorMessage}. Inspect response object for details.`);
        }
      }
    }).catch((e) => {
      if (e.message !== SILENT_ERROR) {
        console.error(e);
      }
    });
    return streamPromise;
  }
};
async function countTokens(apiKey, model, params, singleRequestOptions) {
  const response = await makeModelRequest(model, Task.COUNT_TOKENS, apiKey, false, JSON.stringify(params), singleRequestOptions);
  return response.json();
}
async function embedContent(apiKey, model, params, requestOptions) {
  const response = await makeModelRequest(model, Task.EMBED_CONTENT, apiKey, false, JSON.stringify(params), requestOptions);
  return response.json();
}
async function batchEmbedContents(apiKey, model, params, requestOptions) {
  const requestsWithModel = params.requests.map((request) => {
    return Object.assign(Object.assign({}, request), { model });
  });
  const response = await makeModelRequest(model, Task.BATCH_EMBED_CONTENTS, apiKey, false, JSON.stringify({ requests: requestsWithModel }), requestOptions);
  return response.json();
}
var GenerativeModel = class {
  constructor(apiKey, modelParams, _requestOptions = {}) {
    this.apiKey = apiKey;
    this._requestOptions = _requestOptions;
    if (modelParams.model.includes("/")) {
      this.model = modelParams.model;
    } else {
      this.model = `models/${modelParams.model}`;
    }
    this.generationConfig = modelParams.generationConfig || {};
    this.safetySettings = modelParams.safetySettings || [];
    this.tools = modelParams.tools;
    this.toolConfig = modelParams.toolConfig;
    this.systemInstruction = formatSystemInstruction(modelParams.systemInstruction);
    this.cachedContent = modelParams.cachedContent;
  }
  /**
   * Makes a single non-streaming call to the model
   * and returns an object containing a single {@link GenerateContentResponse}.
   *
   * Fields set in the optional {@link SingleRequestOptions} parameter will
   * take precedence over the {@link RequestOptions} values provided to
   * {@link GoogleGenerativeAI.getGenerativeModel }.
   */
  async generateContent(request, requestOptions = {}) {
    var _a;
    const formattedParams = formatGenerateContentInput(request);
    const generativeModelRequestOptions = Object.assign(Object.assign({}, this._requestOptions), requestOptions);
    return generateContent(this.apiKey, this.model, Object.assign({ generationConfig: this.generationConfig, safetySettings: this.safetySettings, tools: this.tools, toolConfig: this.toolConfig, systemInstruction: this.systemInstruction, cachedContent: (_a = this.cachedContent) === null || _a === void 0 ? void 0 : _a.name }, formattedParams), generativeModelRequestOptions);
  }
  /**
   * Makes a single streaming call to the model and returns an object
   * containing an iterable stream that iterates over all chunks in the
   * streaming response as well as a promise that returns the final
   * aggregated response.
   *
   * Fields set in the optional {@link SingleRequestOptions} parameter will
   * take precedence over the {@link RequestOptions} values provided to
   * {@link GoogleGenerativeAI.getGenerativeModel }.
   */
  async generateContentStream(request, requestOptions = {}) {
    var _a;
    const formattedParams = formatGenerateContentInput(request);
    const generativeModelRequestOptions = Object.assign(Object.assign({}, this._requestOptions), requestOptions);
    return generateContentStream(this.apiKey, this.model, Object.assign({ generationConfig: this.generationConfig, safetySettings: this.safetySettings, tools: this.tools, toolConfig: this.toolConfig, systemInstruction: this.systemInstruction, cachedContent: (_a = this.cachedContent) === null || _a === void 0 ? void 0 : _a.name }, formattedParams), generativeModelRequestOptions);
  }
  /**
   * Gets a new {@link ChatSession} instance which can be used for
   * multi-turn chats.
   */
  startChat(startChatParams) {
    var _a;
    return new ChatSession(this.apiKey, this.model, Object.assign({ generationConfig: this.generationConfig, safetySettings: this.safetySettings, tools: this.tools, toolConfig: this.toolConfig, systemInstruction: this.systemInstruction, cachedContent: (_a = this.cachedContent) === null || _a === void 0 ? void 0 : _a.name }, startChatParams), this._requestOptions);
  }
  /**
   * Counts the tokens in the provided request.
   *
   * Fields set in the optional {@link SingleRequestOptions} parameter will
   * take precedence over the {@link RequestOptions} values provided to
   * {@link GoogleGenerativeAI.getGenerativeModel }.
   */
  async countTokens(request, requestOptions = {}) {
    const formattedParams = formatCountTokensInput(request, {
      model: this.model,
      generationConfig: this.generationConfig,
      safetySettings: this.safetySettings,
      tools: this.tools,
      toolConfig: this.toolConfig,
      systemInstruction: this.systemInstruction,
      cachedContent: this.cachedContent
    });
    const generativeModelRequestOptions = Object.assign(Object.assign({}, this._requestOptions), requestOptions);
    return countTokens(this.apiKey, this.model, formattedParams, generativeModelRequestOptions);
  }
  /**
   * Embeds the provided content.
   *
   * Fields set in the optional {@link SingleRequestOptions} parameter will
   * take precedence over the {@link RequestOptions} values provided to
   * {@link GoogleGenerativeAI.getGenerativeModel }.
   */
  async embedContent(request, requestOptions = {}) {
    const formattedParams = formatEmbedContentInput(request);
    const generativeModelRequestOptions = Object.assign(Object.assign({}, this._requestOptions), requestOptions);
    return embedContent(this.apiKey, this.model, formattedParams, generativeModelRequestOptions);
  }
  /**
   * Embeds an array of {@link EmbedContentRequest}s.
   *
   * Fields set in the optional {@link SingleRequestOptions} parameter will
   * take precedence over the {@link RequestOptions} values provided to
   * {@link GoogleGenerativeAI.getGenerativeModel }.
   */
  async batchEmbedContents(batchEmbedContentRequest, requestOptions = {}) {
    const generativeModelRequestOptions = Object.assign(Object.assign({}, this._requestOptions), requestOptions);
    return batchEmbedContents(this.apiKey, this.model, batchEmbedContentRequest, generativeModelRequestOptions);
  }
};
var GoogleGenerativeAI = class {
  constructor(apiKey) {
    this.apiKey = apiKey;
  }
  /**
   * Gets a {@link GenerativeModel} instance for the provided model name.
   */
  getGenerativeModel(modelParams, requestOptions) {
    if (!modelParams.model) {
      throw new GoogleGenerativeAIError(`Must provide a model name. Example: genai.getGenerativeModel({ model: 'my-model-name' })`);
    }
    return new GenerativeModel(this.apiKey, modelParams, requestOptions);
  }
  /**
   * Creates a {@link GenerativeModel} instance from provided content cache.
   */
  getGenerativeModelFromCachedContent(cachedContent, modelParams, requestOptions) {
    if (!cachedContent.name) {
      throw new GoogleGenerativeAIRequestInputError("Cached content must contain a `name` field.");
    }
    if (!cachedContent.model) {
      throw new GoogleGenerativeAIRequestInputError("Cached content must contain a `model` field.");
    }
    const disallowedDuplicates = ["model", "systemInstruction"];
    for (const key of disallowedDuplicates) {
      if ((modelParams === null || modelParams === void 0 ? void 0 : modelParams[key]) && cachedContent[key] && (modelParams === null || modelParams === void 0 ? void 0 : modelParams[key]) !== cachedContent[key]) {
        if (key === "model") {
          const modelParamsComp = modelParams.model.startsWith("models/") ? modelParams.model.replace("models/", "") : modelParams.model;
          const cachedContentComp = cachedContent.model.startsWith("models/") ? cachedContent.model.replace("models/", "") : cachedContent.model;
          if (modelParamsComp === cachedContentComp) {
            continue;
          }
        }
        throw new GoogleGenerativeAIRequestInputError(`Different value for "${key}" specified in modelParams (${modelParams[key]}) and cachedContent (${cachedContent[key]})`);
      }
    }
    const modelParamsFromCache = Object.assign(Object.assign({}, modelParams), { model: cachedContent.model, tools: cachedContent.tools, toolConfig: cachedContent.toolConfig, systemInstruction: cachedContent.systemInstruction, cachedContent });
    return new GenerativeModel(this.apiKey, modelParamsFromCache, requestOptions);
  }
};

// src/gemini-service.ts
var GeminiService = class {
  constructor(apiKey, settings) {
    this.settings = settings;
    this.genAI = new GoogleGenerativeAI(apiKey);
    this.initializeModels();
  }
  initializeModels() {
    this.embeddingModel = this.genAI.getGenerativeModel({
      model: this.settings.embeddingModel || "text-embedding-004"
    });
    this.chatModel = this.genAI.getGenerativeModel({
      model: this.settings.model || "gemini-2.0-flash",
      generationConfig: {
        temperature: this.settings.temperature || 0.7,
        topK: 40,
        topP: 0.95,
        maxOutputTokens: 8192
      }
    });
  }
  updateSettings(settings) {
    this.settings = settings;
    if (settings.geminiApiKey) {
      this.genAI = new GoogleGenerativeAI(settings.geminiApiKey);
      this.initializeModels();
    }
  }
  async generateEmbedding(text) {
    try {
      const cleanText = text.trim().substring(0, 1e4);
      if (!cleanText) {
        return [];
      }
      const result = await this.embeddingModel.embedContent(cleanText);
      return result.embedding.values;
    } catch (error) {
      console.error("Error generating embedding:", error);
      throw new Error(`Failed to generate embedding: ${error.message}`);
    }
  }
  async generateEmbeddings(texts) {
    const embeddings = [];
    const batchSize = 5;
    for (let i = 0; i < texts.length; i += batchSize) {
      const batch = texts.slice(i, i + batchSize);
      const batchPromises = batch.map((text) => this.generateEmbedding(text));
      try {
        const batchResults = await Promise.all(batchPromises);
        embeddings.push(...batchResults);
      } catch (error) {
        console.error(`Error in batch ${i / batchSize}:`, error);
        embeddings.push(...batch.map(() => []));
      }
      if (i + batchSize < texts.length) {
        await new Promise((resolve) => setTimeout(resolve, 200));
      }
    }
    return embeddings;
  }
  async chat(messages, context) {
    try {
      let systemPrompt = `You are a helpful assistant that answers questions about the user's Obsidian notes.
			Use the following relevant note excerpts to answer the user's question.
			Always cite which notes you're referencing when providing information. If you are not using notes then say that you are not.

			Relevant notes context:
			${context.map((note, i) => `[Note ${i + 1}]: ${note}`).join("\n\n")}

			Now answer the user's question based on the above context.`;
      const formattedMessages = messages.map((msg) => ({
        role: msg.role === "user" ? "user" : "model",
        parts: [{ text: msg.content }]
      }));
      if (context.length > 0) {
        formattedMessages.unshift({
          role: "user",
          parts: [{ text: systemPrompt }]
        }, {
          role: "model",
          parts: [{ text: "I understand. I'll answer questions based on the provided note excerpts and cite my sources." }]
        });
      }
      const chat = this.chatModel.startChat({
        history: formattedMessages.slice(0, -1),
        // All messages except the last one
        generationConfig: {
          temperature: this.settings.temperature || 0.7,
          topK: 40,
          topP: 0.95,
          maxOutputTokens: 8192
        }
      });
      const lastMessage = messages[messages.length - 1];
      const result = await chat.sendMessage(lastMessage.content);
      const response = await result.response;
      return response.text();
    } catch (error) {
      console.error("Chat error:", error);
      throw new Error(`Chat failed: ${error.message}`);
    }
  }
  async testConnection() {
    try {
      const test = await this.generateEmbedding("test");
      return test && test.length > 0;
    } catch (error) {
      console.error("Connection test failed:", error);
      return false;
    }
  }
};

// src/vector-db.ts
var VectorDatabase = class {
  constructor(app, plugin) {
    this.loaded = false;
    this.app = app;
    this.plugin = plugin;
    this.dbPath = ".obsidian/plugins/gemini-vector-chat/vectors.json";
    this.db = /* @__PURE__ */ new Map();
    this.loadDatabase();
  }
  async loadDatabase() {
    try {
      const adapter = this.app.vault.adapter;
      if (await adapter.exists(this.dbPath)) {
        const data = await adapter.read(this.dbPath);
        const parsed = JSON.parse(data);
        if (parsed.vectors && Array.isArray(parsed.vectors)) {
          parsed.vectors.forEach((entry) => {
            this.db.set(entry.id, entry);
          });
        }
      }
      this.loaded = true;
    } catch (error) {
      console.error("Error loading vector database:", error);
      this.db = /* @__PURE__ */ new Map();
      this.loaded = true;
    }
  }
  async saveDatabase() {
    try {
      const adapter = this.app.vault.adapter;
      const dir = this.dbPath.substring(0, this.dbPath.lastIndexOf("/"));
      if (!await adapter.exists(dir)) {
        await adapter.mkdir(dir);
      }
      const data = {
        version: "1.0.0",
        lastUpdated: new Date().toISOString(),
        vectors: Array.from(this.db.values())
      };
      await adapter.write(this.dbPath, JSON.stringify(data, null, 2));
    } catch (error) {
      console.error("Error saving vector database:", error);
      throw error;
    }
  }
  async addVector(entry) {
    if (!this.loaded) {
      await this.loadDatabase();
    }
    this.db.set(entry.id, entry);
    await this.saveDatabase();
  }
  async addVectors(entries) {
    if (!this.loaded) {
      await this.loadDatabase();
    }
    entries.forEach((entry) => {
      this.db.set(entry.id, entry);
    });
    await this.saveDatabase();
  }
  async removeVector(id) {
    if (!this.loaded) {
      await this.loadDatabase();
    }
    this.db.delete(id);
    await this.saveDatabase();
  }
  async getVector(id) {
    if (!this.loaded) {
      await this.loadDatabase();
    }
    return this.db.get(id);
  }
  async search(queryEmbedding, topK = 5) {
    if (!this.loaded) {
      await this.loadDatabase();
    }
    if (!queryEmbedding || queryEmbedding.length === 0) {
      return [];
    }
    const results = [];
    for (const entry of this.db.values()) {
      if (entry.embedding && entry.embedding.length > 0) {
        const similarity = this.cosineSimilarity(queryEmbedding, entry.embedding);
        results.push({ note: entry, similarity });
      }
    }
    results.sort((a, b) => b.similarity - a.similarity);
    return results.slice(0, topK);
  }
  cosineSimilarity(a, b) {
    if (a.length !== b.length) {
      console.warn("Vector length mismatch:", a.length, "vs", b.length);
      return 0;
    }
    let dotProduct = 0;
    let normA = 0;
    let normB = 0;
    for (let i = 0; i < a.length; i++) {
      dotProduct += a[i] * b[i];
      normA += a[i] * a[i];
      normB += b[i] * b[i];
    }
    if (normA === 0 || normB === 0) {
      return 0;
    }
    return dotProduct / (Math.sqrt(normA) * Math.sqrt(normB));
  }
  async clear() {
    this.db.clear();
    await this.saveDatabase();
  }
  async getStats() {
    if (!this.loaded) {
      await this.loadDatabase();
    }
    let lastUpdated = null;
    if (this.db.size > 0) {
      let latestTime = 0;
      for (const entry of this.db.values()) {
        if (entry.modified > latestTime) {
          latestTime = entry.modified;
        }
      }
      if (latestTime > 0) {
        lastUpdated = new Date(latestTime).toLocaleString();
      }
    }
    return {
      totalNotes: this.db.size,
      lastUpdated
    };
  }
  async getAllNoteIds() {
    if (!this.loaded) {
      await this.loadDatabase();
    }
    return Array.from(this.db.keys());
  }
  async needsReindexing() {
    if (!this.loaded) {
      await this.loadDatabase();
    }
    if (this.db.size === 0) {
      return true;
    }
    const files = this.app.vault.getMarkdownFiles();
    if (files.length !== this.db.size) {
      return true;
    }
    const samplSize = Math.min(10, files.length);
    for (let i = 0; i < samplSize; i++) {
      const file = files[Math.floor(Math.random() * files.length)];
      const entry = this.db.get(file.path);
      if (!entry || file.stat.mtime > entry.modified) {
        return true;
      }
    }
    return false;
  }
  async getModifiedNotes() {
    if (!this.loaded) {
      await this.loadDatabase();
    }
    const modifiedFiles = [];
    const files = this.app.vault.getMarkdownFiles();
    for (const file of files) {
      const entry = this.db.get(file.path);
      if (!entry || file.stat.mtime > entry.modified) {
        modifiedFiles.push(file);
      }
    }
    return modifiedFiles;
  }
  async removeDeletedNotes() {
    if (!this.loaded) {
      await this.loadDatabase();
    }
    const files = this.app.vault.getMarkdownFiles();
    const currentPaths = new Set(files.map((f) => f.path));
    const toDelete = [];
    for (const id of this.db.keys()) {
      if (!currentPaths.has(id)) {
        toDelete.push(id);
      }
    }
    for (const id of toDelete) {
      this.db.delete(id);
    }
    if (toDelete.length > 0) {
      await this.saveDatabase();
    }
    return toDelete.length;
  }
};

// src/chat-view.ts
var import_obsidian = require("obsidian");
var VIEW_TYPE_GEMINI_CHAT = "gemini-chat-view";
var ChatView = class extends import_obsidian.ItemView {
  constructor(leaf, plugin) {
    super(leaf);
    this.messages = [];
    this.isProcessing = false;
    this.plugin = plugin;
  }
  getViewType() {
    return VIEW_TYPE_GEMINI_CHAT;
  }
  getDisplayText() {
    return "Gemini Chat";
  }
  getIcon() {
    return "message-square";
  }
  async onOpen() {
    const container = this.containerEl.children[1];
    container.empty();
    container.addClass("gemini-chat-container");
    this.createHeader(container);
    this.createChatArea(container);
    this.createInputArea(container);
    this.loadChatHistory();
  }
  createHeader(container) {
    const header = container.createDiv("gemini-chat-header");
    const title = header.createEl("h4", { text: "Chat with your notes" });
    const actions = header.createDiv("gemini-chat-actions");
    const clearBtn = actions.createEl("button", {
      text: "Clear Chat",
      cls: "mod-cta"
    });
    clearBtn.onclick = () => this.clearChat();
    const indexBtn = actions.createEl("button", {
      text: "Index Notes",
      cls: "mod-cta"
    });
    indexBtn.onclick = async () => {
      indexBtn.disabled = true;
      indexBtn.textContent = "Indexing...";
      try {
        const count = await this.plugin.indexer.indexAllNotes();
        new import_obsidian.Notice(`Indexed ${count} notes`);
      } catch (error) {
        new import_obsidian.Notice("Indexing failed");
      } finally {
        indexBtn.disabled = false;
        indexBtn.textContent = "Index Notes";
      }
    };
  }
  createChatArea(container) {
    this.chatContainer = container.createDiv("gemini-chat-messages");
    if (this.messages.length === 0) {
      this.addWelcomeMessage();
    }
  }
  createInputArea(container) {
    this.inputContainer = container.createDiv("gemini-chat-input-area");
    this.inputField = this.inputContainer.createEl("textarea", {
      placeholder: "Ask a question about your notes...",
      cls: "gemini-chat-input"
    });
    this.inputField.addEventListener("input", () => {
      this.inputField.style.height = "auto";
      this.inputField.style.height = this.inputField.scrollHeight + "px";
    });
    this.inputField.addEventListener("keydown", (e) => {
      if (e.key === "Enter" && !e.shiftKey) {
        e.preventDefault();
        this.sendMessage();
      }
    });
    const buttonContainer = this.inputContainer.createDiv("gemini-chat-button-container");
    this.sendButton = buttonContainer.createEl("button", {
      text: "Send",
      cls: "mod-cta gemini-send-button"
    });
    this.sendButton.onclick = () => this.sendMessage();
  }
  addWelcomeMessage() {
    const welcomeDiv = this.chatContainer.createDiv("gemini-message gemini-assistant-message");
    welcomeDiv.createEl("div", {
      cls: "gemini-message-content",
      text: 'Hello! I can help you explore and find information in your notes. Make sure to index your notes first using the "Index Notes" button above. Then ask me any question!'
    });
  }
  async sendMessage() {
    const input = this.inputField.value.trim();
    if (!input || this.isProcessing) {
      return;
    }
    if (!this.plugin.settings.geminiApiKey) {
      new import_obsidian.Notice("Please configure your Gemini API key in settings");
      return;
    }
    this.isProcessing = true;
    this.inputField.disabled = true;
    this.sendButton.disabled = true;
    this.sendButton.textContent = "Processing...";
    this.addMessage("user", input);
    this.inputField.value = "";
    this.inputField.style.height = "auto";
    try {
      const queryEmbedding = await this.plugin.geminiService.generateEmbedding(input);
      const searchResults = await this.plugin.vectorDb.search(
        queryEmbedding,
        this.plugin.settings.topK || 5
      );
      const context = this.extractContext(searchResults);
      if (this.plugin.settings.showDebugInfo && searchResults.length > 0) {
        this.addDebugInfo(searchResults);
      }
      const response = await this.plugin.geminiService.chat(
        this.messages,
        context
      );
      this.addMessage("assistant", response);
    } catch (error) {
      console.error("Chat error:", error);
      this.addMessage("assistant", `I encountered an error: ${error.message}`);
      new import_obsidian.Notice("Chat failed: " + error.message);
    } finally {
      this.isProcessing = false;
      this.inputField.disabled = false;
      this.sendButton.disabled = false;
      this.sendButton.textContent = "Send";
      this.inputField.focus();
    }
    this.saveChatHistory();
  }
  addMessage(role, content) {
    this.messages.push({ role, content });
    const messageDiv = this.chatContainer.createDiv(`gemini-message gemini-${role}-message`);
    const roleLabel = messageDiv.createDiv("gemini-message-role");
    roleLabel.textContent = role === "user" ? "You" : "Gemini";
    const contentDiv = messageDiv.createDiv("gemini-message-content");
    if (role === "assistant") {
      import_obsidian.MarkdownRenderer.renderMarkdown(content, contentDiv, "", this);
    } else {
      contentDiv.textContent = content;
    }
    this.chatContainer.scrollTop = this.chatContainer.scrollHeight;
  }
  addDebugInfo(results) {
    const debugDiv = this.chatContainer.createDiv("gemini-debug-info");
    debugDiv.createEl("div", {
      cls: "gemini-debug-title",
      text: "Found relevant notes:"
    });
    const list = debugDiv.createEl("ul");
    results.forEach((result) => {
      const item = list.createEl("li");
      item.createEl("span", {
        text: `${result.note.title} (similarity: ${result.similarity.toFixed(3)})`
      });
    });
  }
  extractContext(results) {
    return results.map((result) => {
      const noteInfo = `Note: "${result.note.title}" (${result.note.id})
`;
      const content = result.note.content;
      return noteInfo + content;
    });
  }
  clearChat() {
    this.messages = [];
    this.chatContainer.empty();
    this.addWelcomeMessage();
    this.saveChatHistory();
  }
  async saveChatHistory() {
    try {
      const data = {
        messages: this.messages,
        timestamp: Date.now()
      };
      await this.plugin.saveData({ chatHistory: data });
    } catch (error) {
      console.error("Failed to save chat history:", error);
    }
  }
  async loadChatHistory() {
    try {
      const data = await this.plugin.loadData();
      if (data && data.chatHistory && data.chatHistory.messages) {
        this.messages = data.chatHistory.messages;
        this.chatContainer.empty();
        if (this.messages.length === 0) {
          this.addWelcomeMessage();
        } else {
          this.messages.forEach((msg) => {
            this.renderMessage(msg);
          });
        }
      }
    } catch (error) {
      console.error("Failed to load chat history:", error);
    }
  }
  renderMessage(message) {
    const messageDiv = this.chatContainer.createDiv(`gemini-message gemini-${message.role}-message`);
    const roleLabel = messageDiv.createDiv("gemini-message-role");
    roleLabel.textContent = message.role === "user" ? "You" : "Gemini";
    const contentDiv = messageDiv.createDiv("gemini-message-content");
    if (message.role === "assistant") {
      import_obsidian.MarkdownRenderer.renderMarkdown(message.content, contentDiv, "", this);
    } else {
      contentDiv.textContent = message.content;
    }
  }
  async onClose() {
  }
};

// src/indexer.ts
var import_obsidian2 = require("obsidian");
var NoteIndexer = class {
  constructor(app, geminiService, vectorDb, plugin) {
    this.isIndexing = false;
    this.app = app;
    this.geminiService = geminiService;
    this.vectorDb = vectorDb;
    this.plugin = plugin;
  }
  async indexAllNotes(showProgress = true) {
    if (this.isIndexing) {
      new import_obsidian2.Notice("Indexing already in progress");
      return 0;
    }
    this.isIndexing = true;
    let indexed = 0;
    try {
      const deletedCount = await this.vectorDb.removeDeletedNotes();
      if (deletedCount > 0 && showProgress) {
        console.log(`Removed ${deletedCount} deleted notes from index`);
      }
      const files = this.app.vault.getMarkdownFiles();
      const totalFiles = files.length;
      if (totalFiles === 0) {
        new import_obsidian2.Notice("No notes found to index");
        return 0;
      }
      if (showProgress) {
        new import_obsidian2.Notice(`Starting to index ${totalFiles} notes...`);
      }
      const batchSize = 5;
      const entries = [];
      for (let i = 0; i < files.length; i += batchSize) {
        const batch = files.slice(i, i + batchSize);
        const batchEntries = await this.processBatch(batch);
        entries.push(...batchEntries);
        indexed += batchEntries.length;
        if (showProgress && i % 10 === 0) {
          const progress = Math.round(i / totalFiles * 100);
          new import_obsidian2.Notice(`Indexing progress: ${progress}%`, 2e3);
        }
      }
      if (entries.length > 0) {
        await this.vectorDb.addVectors(entries);
      }
      if (showProgress) {
        new import_obsidian2.Notice(`Successfully indexed ${indexed} notes!`);
      }
      return indexed;
    } catch (error) {
      console.error("Indexing error:", error);
      new import_obsidian2.Notice(`Indexing failed: ${error.message}`);
      throw error;
    } finally {
      this.isIndexing = false;
    }
  }
  async indexModifiedNotes() {
    if (this.isIndexing) {
      return 0;
    }
    this.isIndexing = true;
    let indexed = 0;
    try {
      const modifiedFiles = await this.vectorDb.getModifiedNotes();
      if (modifiedFiles.length === 0) {
        return 0;
      }
      console.log(`Found ${modifiedFiles.length} modified notes to index`);
      const entries = await this.processBatch(modifiedFiles);
      if (entries.length > 0) {
        await this.vectorDb.addVectors(entries);
        indexed = entries.length;
      }
      return indexed;
    } catch (error) {
      console.error("Incremental indexing error:", error);
      throw error;
    } finally {
      this.isIndexing = false;
    }
  }
  async processBatch(files) {
    const entries = [];
    const contents = [];
    const fileData = [];
    for (const file of files) {
      try {
        const content = await this.app.vault.cachedRead(file);
        const processedContent = this.preprocessContent(content, file);
        if (processedContent.trim()) {
          contents.push(processedContent);
          fileData.push({ file, content: processedContent });
        }
      } catch (error) {
        console.error(`Error reading file ${file.path}:`, error);
      }
    }
    if (contents.length === 0) {
      return entries;
    }
    try {
      const embeddings = await this.geminiService.generateEmbeddings(contents);
      for (let i = 0; i < fileData.length; i++) {
        const { file, content } = fileData[i];
        const embedding = embeddings[i];
        if (embedding && embedding.length > 0) {
          entries.push({
            id: file.path,
            embedding,
            content: content.substring(0, 3e3),
            // Store first 3000 chars for context
            title: file.basename,
            modified: file.stat.mtime,
            tags: this.extractTags(content)
          });
        }
      }
    } catch (error) {
      console.error("Error generating embeddings:", error);
    }
    return entries;
  }
  preprocessContent(content, file) {
    content = content.replace(/^---[\s\S]*?---\n?/m, "");
    content = content.replace(/```[\s\S]*?```/g, "[code block]");
    content = content.replace(/`[^`]+`/g, "[inline code]");
    content = content.replace(/^#+\s+/gm, "");
    content = content.replace(/\[([^\]]+)\]\([^)]+\)/g, "$1");
    content = content.replace(/!\[([^\]]*)\]\([^)]+\)/g, "[image: $1]");
    content = content.replace(/\*\*([^*]+)\*\*/g, "$1");
    content = content.replace(/\*([^*]+)\*/g, "$1");
    content = content.replace(/__([^_]+)__/g, "$1");
    content = content.replace(/_([^_]+)_/g, "$1");
    content = `Title: ${file.basename}
Path: ${file.path}

${content}`;
    content = content.replace(/\n{3,}/g, "\n\n");
    content = content.trim();
    return content;
  }
  extractTags(content) {
    const tags = [];
    const hashtagMatches = content.match(/#[\w-]+/g);
    if (hashtagMatches) {
      tags.push(...hashtagMatches.map((tag) => tag.substring(1)));
    }
    const frontmatterMatch = content.match(/^---\n([\s\S]*?)\n---/);
    if (frontmatterMatch) {
      const frontmatter = frontmatterMatch[1];
      const tagsMatch = frontmatter.match(/tags:\s*\[(.*?)\]/);
      if (tagsMatch) {
        const tagList = tagsMatch[1].split(",").map((t) => t.trim().replace(/['"]/g, ""));
        tags.push(...tagList);
      }
    }
    return [...new Set(tags)];
  }
  async indexSingleNote(file) {
    try {
      const entries = await this.processBatch([file]);
      if (entries.length > 0) {
        await this.vectorDb.addVector(entries[0]);
        return true;
      }
      return false;
    } catch (error) {
      console.error(`Error indexing ${file.path}:`, error);
      return false;
    }
  }
  isCurrentlyIndexing() {
    return this.isIndexing;
  }
};

// main.ts
var DEFAULT_SETTINGS = {
  geminiApiKey: "",
  model: "gemini-2.0-flash",
  embeddingModel: "text-embedding-004",
  temperature: 0.7,
  topK: 5,
  autoIndex: true,
  showDebugInfo: false
};
var GeminiVectorChatPlugin = class extends import_obsidian3.Plugin {
  constructor() {
    super(...arguments);
    this.chatView = null;
  }
  async onload() {
    await this.loadSettings();
    if (!this.settings.geminiApiKey) {
      new import_obsidian3.Notice("\u26A0\uFE0F Gemini API key not configured. Please add your API key in settings.");
    }
    this.geminiService = new GeminiService(this.settings.geminiApiKey || "placeholder", this.settings);
    this.vectorDb = new VectorDatabase(this.app, this);
    this.indexer = new NoteIndexer(this.app, this.geminiService, this.vectorDb, this);
    this.registerView(
      VIEW_TYPE_GEMINI_CHAT,
      (leaf) => {
        this.chatView = new ChatView(leaf, this);
        return this.chatView;
      }
    );
    const ribbonIconEl = this.addRibbonIcon("message-square", "Gemini Chat", (evt) => {
      this.activateChatView();
    });
    this.addCommand({
      id: "open-gemini-chat",
      name: "Open Gemini Chat",
      callback: () => {
        this.activateChatView();
      }
    });
    this.addCommand({
      id: "index-all-notes",
      name: "Index all notes for semantic search",
      callback: async () => {
        new import_obsidian3.Notice("Starting indexing process...");
        try {
          const count = await this.indexer.indexAllNotes();
          new import_obsidian3.Notice(`Successfully indexed ${count} notes!`);
        } catch (error) {
          console.error("Indexing error:", error);
          new import_obsidian3.Notice(`Indexing failed: ${error.message}`);
        }
      }
    });
    this.addCommand({
      id: "clear-vector-database",
      name: "Clear vector database",
      callback: async () => {
        try {
          await this.vectorDb.clear();
          new import_obsidian3.Notice("Vector database cleared successfully");
        } catch (error) {
          new import_obsidian3.Notice(`Failed to clear database: ${error.message}`);
        }
      }
    });
    this.addSettingTab(new GeminiVectorChatSettingTab(this.app, this));
    if (this.settings.autoIndex) {
      this.app.workspace.onLayoutReady(async () => {
        const needsIndexing = await this.vectorDb.needsReindexing();
        if (needsIndexing) {
          new import_obsidian3.Notice("Auto-indexing notes for Gemini Chat...");
          try {
            const count = await this.indexer.indexAllNotes();
            new import_obsidian3.Notice(`Indexed ${count} notes successfully`);
          } catch (error) {
            console.error("Auto-indexing error:", error);
          }
        }
      });
    }
  }
  async activateChatView() {
    const { workspace } = this.app;
    let leaf = null;
    const leaves = workspace.getLeavesOfType(VIEW_TYPE_GEMINI_CHAT);
    if (leaves.length > 0) {
      leaf = leaves[0];
    } else {
      const rightLeaf = workspace.getRightLeaf(false);
      if (rightLeaf) {
        leaf = rightLeaf;
      } else {
        leaf = workspace.getLeaf(true);
      }
      if (leaf) {
        await leaf.setViewState({
          type: VIEW_TYPE_GEMINI_CHAT,
          active: true
        });
      }
    }
    if (leaf) {
      workspace.revealLeaf(leaf);
    }
  }
  onunload() {
    this.app.workspace.detachLeavesOfType(VIEW_TYPE_GEMINI_CHAT);
  }
  async loadSettings() {
    this.settings = Object.assign({}, DEFAULT_SETTINGS, await this.loadData());
  }
  async saveSettings() {
    await this.saveData(this.settings);
    this.geminiService.updateSettings(this.settings);
  }
};
var GeminiVectorChatSettingTab = class extends import_obsidian3.PluginSettingTab {
  constructor(app, plugin) {
    super(app, plugin);
    this.plugin = plugin;
  }
  display() {
    const { containerEl } = this;
    containerEl.empty();
    containerEl.createEl("h2", { text: "Gemini Vector Chat Settings" });
    new import_obsidian3.Setting(containerEl).setName("Gemini API Key").setDesc("Enter your Google Gemini API key").addText(
      (text) => text.setPlaceholder("Enter your API key").setValue(this.plugin.settings.geminiApiKey).onChange(async (value) => {
        this.plugin.settings.geminiApiKey = value;
        await this.plugin.saveSettings();
      }).inputEl.type = "password"
    );
    new import_obsidian3.Setting(containerEl).setName("Chat Model").setDesc("Select the Gemini model to use for chat").addDropdown(
      (dropdown) => dropdown.addOption("gemini-2.0-flash", "Gemini 2.0 Flash (Recommended)").addOption("gemini-2.0-flash-002", "Gemini 2.0 Flash v002").addOption("gemini-1.5-flash-002", "Gemini 1.5 Flash v002").addOption("gemini-1.5-pro-002", "Gemini 1.5 Pro v002 (Advanced)").setValue(this.plugin.settings.model).onChange(async (value) => {
        this.plugin.settings.model = value;
        await this.plugin.saveSettings();
      })
    );
    new import_obsidian3.Setting(containerEl).setName("Temperature").setDesc("Controls randomness in responses (0 = deterministic, 1 = creative)").addSlider(
      (slider) => slider.setLimits(0, 1, 0.1).setValue(this.plugin.settings.temperature).setDynamicTooltip().onChange(async (value) => {
        this.plugin.settings.temperature = value;
        await this.plugin.saveSettings();
      })
    );
    new import_obsidian3.Setting(containerEl).setName("Search Results").setDesc("Number of relevant notes to include in context").addSlider(
      (slider) => slider.setLimits(1, 20, 1).setValue(this.plugin.settings.topK).setDynamicTooltip().onChange(async (value) => {
        this.plugin.settings.topK = value;
        await this.plugin.saveSettings();
      })
    );
    new import_obsidian3.Setting(containerEl).setName("Auto-index on startup").setDesc("Automatically index new or modified notes when Obsidian starts").addToggle(
      (toggle) => toggle.setValue(this.plugin.settings.autoIndex).onChange(async (value) => {
        this.plugin.settings.autoIndex = value;
        await this.plugin.saveSettings();
      })
    );
    new import_obsidian3.Setting(containerEl).setName("Show debug information").setDesc("Display technical information in chat (useful for troubleshooting)").addToggle(
      (toggle) => toggle.setValue(this.plugin.settings.showDebugInfo).onChange(async (value) => {
        this.plugin.settings.showDebugInfo = value;
        await this.plugin.saveSettings();
      })
    );
    containerEl.createEl("h3", { text: "Database Statistics" });
    const statsDiv = containerEl.createDiv("gemini-stats");
    this.updateStats(statsDiv);
    containerEl.createEl("h3", { text: "Actions" });
    new import_obsidian3.Setting(containerEl).setName("Index All Notes").setDesc("Build vector embeddings for all notes in your vault").addButton(
      (button) => button.setButtonText("Start Indexing").setCta().onClick(async () => {
        button.setDisabled(true);
        button.setButtonText("Indexing...");
        try {
          const count = await this.plugin.indexer.indexAllNotes();
          new import_obsidian3.Notice(`Successfully indexed ${count} notes!`);
          this.updateStats(statsDiv);
        } catch (error) {
          new import_obsidian3.Notice(`Indexing failed: ${error.message}`);
        } finally {
          button.setButtonText("Start Indexing");
          button.setDisabled(false);
        }
      })
    );
    new import_obsidian3.Setting(containerEl).setName("Clear Database").setDesc("Remove all indexed vectors (you'll need to re-index)").addButton(
      (button) => button.setButtonText("Clear Database").setWarning().onClick(async () => {
        try {
          await this.plugin.vectorDb.clear();
          new import_obsidian3.Notice("Vector database cleared");
          this.updateStats(statsDiv);
        } catch (error) {
          new import_obsidian3.Notice(`Failed to clear: ${error.message}`);
        }
      })
    );
  }
  async updateStats(container) {
    container.empty();
    try {
      const stats = await this.plugin.vectorDb.getStats();
      container.createEl("p", {
        text: `Indexed notes: ${stats.totalNotes} | Last updated: ${stats.lastUpdated || "Never"}`
      });
    } catch (error) {
      container.createEl("p", {
        text: "Unable to load statistics"
      });
    }
  }
};
/*! Bundled license information:

@google/generative-ai/dist/index.mjs:
  (**
   * @license
   * Copyright 2024 Google LLC
   *
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   *   http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   *)

@google/generative-ai/dist/index.mjs:
  (**
   * @license
   * Copyright 2024 Google LLC
   *
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   *   http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   *)
*/
